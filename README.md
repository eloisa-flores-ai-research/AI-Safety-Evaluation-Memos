# AI-Safety-Evaluation-Memos
Qualitative evaluation notes on frontier LLMs behavior and deceptive alignment signals.

AI Safety Evaluation Memos
This repository contains qualitative evaluation notes on frontier Large Language Models (LLMs). 
The research focuses on identifying behavioural anomalies, reasoning shortcuts, and deceptive alignment signals through structured interaction methodologies.

Author: Eloisa Flores
